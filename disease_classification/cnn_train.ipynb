{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = 'dataset/crop_diseases'\n",
    "CACHE_DIR = 'dataset/cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(dataset_path, cache, batch_size=500):\n",
    "    batch_images = []\n",
    "    batch_labels = []\n",
    "    label_map = {}\n",
    "    all_batch_files = []    \n",
    "\n",
    "    # Load from cache if exists\n",
    "    batch_files = [f for f in os.listdir(cache) if f.startswith(\"images_batch_\")]\n",
    "    if batch_files:\n",
    "        print(\"üîÅ Loading cached batches...\")\n",
    "        # load all batches\n",
    "        all_batch_files = []\n",
    "        for batch_index in range(len(batch_files)):\n",
    "            image_file = os.path.join(cache, f'images_batch_{batch_index}.npy')\n",
    "            label_file = os.path.join(cache, f'labels_batch_{batch_index}.npy')\n",
    "            all_batch_files.append((image_file, label_file))\n",
    "            \n",
    "        images = np.concatenate([np.load(file[0]) for file in all_batch_files], axis=0)\n",
    "        labels = np.concatenate([np.load(file[1]) for file in all_batch_files], axis=0)\n",
    "        label_map = np.load(os.path.join(cache, \"label_map.npy\"), allow_pickle=True).item()\n",
    "        print(\"‚úÖ Loaded cached batches.\")\n",
    "        print(f\"üó∫Ô∏è Label map loaded with {len(label_map)} classes.\")\n",
    "        \n",
    "    else:\n",
    "        print(\"üß™ Preprocessing and caching data...\")\n",
    "        if not os.path.exists(cache):\n",
    "            os.makedirs(cache)\n",
    "\n",
    "        class_id = 0\n",
    "        batch_index = 0\n",
    "        for folder_name in os.listdir(dataset_path):\n",
    "            folder_path = os.path.join(dataset_path, folder_name)\n",
    "            if os.path.isdir(folder_path):\n",
    "                label_map[folder_name] = class_id\n",
    "                for image_name in os.listdir(folder_path):\n",
    "                    image_path = os.path.join(folder_path, image_name)\n",
    "                    image = cv2.imread(image_path)\n",
    "                    if image is not None:\n",
    "                        image = cv2.resize(image, (128, 128))\n",
    "                        image = image.astype(np.float32)/ 255.0\n",
    "                        batch_images.append(image)\n",
    "                        batch_labels.append(class_id)\n",
    "                        # Save batch\n",
    "                    if len(batch_images) == batch_size:\n",
    "                        image_file = os.path.join(CACHE_DIR, f'images_batch_{batch_index}.npy')\n",
    "                        label_file = os.path.join(CACHE_DIR, f'labels_batch_{batch_index}.npy')\n",
    "\n",
    "                        np.save(image_file, np.array(batch_images, dtype=np.float32))\n",
    "                        np.save(label_file, np.array(batch_labels))\n",
    "\n",
    "                        all_batch_files.append((image_file, label_file))\n",
    "                        print(f\"‚úÖ Saved batch {batch_index} with {len(batch_images)} images.\")\n",
    "\n",
    "                        batch_images = []\n",
    "                        batch_labels = []\n",
    "                        batch_index += 1\n",
    "                class_id += 1\n",
    "        if batch_images:\n",
    "            image_file = os.path.join(CACHE_DIR, f'images_batch_{batch_index}.npy')\n",
    "            label_file = os.path.join(CACHE_DIR, f'labels_batch_{batch_index}.npy')\n",
    "\n",
    "            np.save(image_file, np.array(batch_images, dtype=np.float32))\n",
    "            np.save(label_file, np.array(batch_labels))\n",
    "\n",
    "            all_batch_files.append((image_file, label_file))\n",
    "            print(f\"‚úÖ Saved final batch {batch_index} with {len(batch_images)} images.\")\n",
    "\n",
    "        np.save(os.path.join(CACHE_DIR, \"label_map.npy\"), label_map)\n",
    "        print(\"üó∫Ô∏è Label map saved.\")\n",
    "        images = np.concatenate([np.load(file[0]) for file in all_batch_files], axis=0)\n",
    "        labels = np.concatenate([np.load(file[1]) for file in all_batch_files], axis=0)\n",
    "    return images, labels, label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ Loading cached batches...\n",
      "‚úÖ Loaded cached batches.\n",
      "üó∫Ô∏è Label map loaded with 71 classes.\n"
     ]
    }
   ],
   "source": [
    "X, y, label_map = load_images(DATASET_PATH, CACHE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=len(label_map))\n",
    "y_val = to_categorical(y_val, num_classes=len(label_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 24086, Validation samples: 6022\n",
      "Label map: {'Cauliflower___Bacterial_spot_rot': 0, 'Cauliflower___Black_Rot': 1, 'Cauliflower___Downy_Mildew': 2, 'Cauliflower___Healthy': 3, 'Coffee___Healthy': 4, 'Coffee___Leaf_Miner': 5, 'Coffee___Phoma': 6, 'Coffee___Red_Spider_Mite': 7, 'Coffee___Rust': 8, 'Corn_(maize)___Cercospora_Leaf_Spot': 9, 'Corn_(maize)___Common_Rust': 10, 'Corn_(maize)___Healthy': 11, 'Corn_(maize)___Northern_Leaf_Blight': 12, 'Cotton___Aphids': 13, 'Cotton___Army_Worm': 14, 'Cotton___Bacterial_Blight': 15, 'Cotton___Healthy': 16, 'Cotton___Powdery_Mildew': 17, 'Cotton___Target_Spot': 18, 'Eggplant___Healthy': 19, 'Eggplant___Insect_Pest': 20, 'Eggplant___Leaf_Spot': 21, 'Eggplant___Mosaic_Virus': 22, 'Eggplant___White_Mold': 23, 'Eggplant___Wilt': 24, 'Mango___Anthracnose': 25, 'Mango___Bacterial_Canker': 26, 'Mango___Die_Back': 27, 'Mango___Gall_Midge': 28, 'Mango___Healthy': 29, 'Mango___Powdery_Mildew': 30, 'Mango___Sooty_Mould': 31, 'Potato___Early_Blight': 32, 'Potato___Healthy': 33, 'Potato___Late_Blight': 34, 'Rice___Bacterial_Leaf_Blight': 35, 'Rice___Brown_Spot': 36, 'Rice___Healthy': 37, 'Rice___Hispa': 38, 'Rice___Leaf_Blast': 39, 'Rice___Leaf_scald': 40, 'Rice___Narrow_Brown_Leaf_Spot': 41, 'Rice___Sheath_Blight': 42, 'Sugarcane___BacterialBlights': 43, 'Sugarcane___Healthy': 44, 'Sugarcane___Mosaic': 45, 'Sugarcane___RedRot': 46, 'Sugarcane___Rust': 47, 'Sugarcane___Yellow': 48, 'Tea___Algal_Leaf_Spot': 49, 'Tea___Brown_Blight': 50, 'Tea___Gray_Blight': 51, 'Tea___Green_Mirid_Bug': 52, 'Tea___Healthy': 53, 'Tea___Helopeltis': 54, 'Tea___Red_spider': 55, 'Tomato___Bacterial_spot': 56, 'Tomato___Early_Blight': 57, 'Tomato___Healthy': 58, 'Tomato___Late_Blight': 59, 'Tomato___Leaf_Mold': 60, 'Tomato___Mosaic_Virus': 61, 'Tomato___Septoria_Leaf_Spot': 62, 'Tomato___Spider_Mites': 63, 'Tomato___Target_Spot': 64, 'Tomato___Yellow_Leaf_Curl_Virus': 65, 'Wheat___Brown_Rust': 66, 'Wheat___Healthy': 67, 'Wheat___Loose_Smut': 68, 'Wheat___Septoria': 69, 'Wheat___Yellow_Rust': 70}\n",
      "Number of classes: 71\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training samples: {len(X_train)}, Validation samples: {len(X_val)}\")\n",
    "print(f\"Label map: {label_map}\")\n",
    "print(f\"Number of classes: {len(label_map)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "val_datagen = ImageDataGenerator()\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=32)\n",
    "val_generator = val_datagen.flow(X_val, y_val, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 128, 128, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128, 128, 32)     128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 128, 128, 32)      9248      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 128, 128, 32)     128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 64, 64, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 64, 64, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 64, 64, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 64, 64, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 64, 64, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 32, 32, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 32, 32, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 32, 32, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 32, 32, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 32, 32, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 16, 16, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 128)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 71)                18247     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 340,071\n",
      "Trainable params: 339,175\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn = Sequential()\n",
    "\n",
    "# Block 1\n",
    "cnn.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(128, 128, 3),\n",
    "               kernel_regularizer=regularizers.l2(0.001)))\n",
    "cnn.add(BatchNormalization())\n",
    "cnn.add(Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001)))\n",
    "cnn.add(BatchNormalization())\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn.add(Dropout(0.25))\n",
    "\n",
    "# Block 2\n",
    "cnn.add(Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001)))\n",
    "cnn.add(BatchNormalization())\n",
    "cnn.add(Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001)))\n",
    "cnn.add(BatchNormalization())\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn.add(Dropout(0.3))\n",
    "\n",
    "# Block 3\n",
    "cnn.add(Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001)))\n",
    "cnn.add(BatchNormalization())\n",
    "cnn.add(Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001)))\n",
    "cnn.add(BatchNormalization())\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn.add(Dropout(0.4))\n",
    "\n",
    "# Replace Flatten with GlobalAveragePooling2D\n",
    "cnn.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Fully Connected Layer\n",
    "cnn.add(Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "cnn.add(Dropout(0.5))\n",
    "\n",
    "# Output Layer\n",
    "cnn.add(Dense(len(label_map), activation='softmax'))\n",
    "\n",
    "# Compile\n",
    "cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',     # Watch validation loss\n",
    "    patience=5,             # If val_loss doesn't improve for 5 epochs, stop\n",
    "    restore_best_weights=True,  # Restore the best model weights automatically\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Define ModelCheckpoint callback (to save best model during training)\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'model/crop_disease_best_model.h5',  # Save the model with the best validation loss\n",
    "    monitor='val_loss',   # Monitor validation loss\n",
    "    save_best_only=True,  # Save only the model with the best validation loss\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "752/752 [==============================] - ETA: 0s - loss: 2.8229 - accuracy: 0.2963\n",
      "Epoch 1: val_loss improved from inf to 3.24849, saving model to model\\crop_disease_best_model.h5\n",
      "752/752 [==============================] - 687s 911ms/step - loss: 2.8229 - accuracy: 0.2963 - val_loss: 3.2485 - val_accuracy: 0.2957\n",
      "Epoch 2/20\n",
      "752/752 [==============================] - ETA: 0s - loss: 2.0444 - accuracy: 0.4525\n",
      "Epoch 2: val_loss improved from 3.24849 to 2.04735, saving model to model\\crop_disease_best_model.h5\n",
      "752/752 [==============================] - 688s 915ms/step - loss: 2.0444 - accuracy: 0.4525 - val_loss: 2.0473 - val_accuracy: 0.4315\n",
      "Epoch 3/20\n",
      "752/752 [==============================] - ETA: 0s - loss: 1.7508 - accuracy: 0.5247\n",
      "Epoch 3: val_loss improved from 2.04735 to 1.61491, saving model to model\\crop_disease_best_model.h5\n",
      "752/752 [==============================] - 632s 840ms/step - loss: 1.7508 - accuracy: 0.5247 - val_loss: 1.6149 - val_accuracy: 0.5700\n",
      "Epoch 4/20\n",
      "752/752 [==============================] - ETA: 0s - loss: 1.6278 - accuracy: 0.5593\n",
      "Epoch 4: val_loss did not improve from 1.61491\n",
      "752/752 [==============================] - 629s 837ms/step - loss: 1.6278 - accuracy: 0.5593 - val_loss: 1.8005 - val_accuracy: 0.5115\n",
      "Epoch 5/20\n",
      "752/752 [==============================] - ETA: 0s - loss: 1.4937 - accuracy: 0.5978\n",
      "Epoch 5: val_loss improved from 1.61491 to 1.57300, saving model to model\\crop_disease_best_model.h5\n",
      "752/752 [==============================] - 584s 777ms/step - loss: 1.4937 - accuracy: 0.5978 - val_loss: 1.5730 - val_accuracy: 0.5914\n",
      "Epoch 6/20\n",
      "752/752 [==============================] - ETA: 0s - loss: 1.4057 - accuracy: 0.6251 \n",
      "Epoch 6: val_loss did not improve from 1.57300\n",
      "752/752 [==============================] - 21543s 29s/step - loss: 1.4057 - accuracy: 0.6251 - val_loss: 1.8616 - val_accuracy: 0.5231\n",
      "Epoch 7/20\n",
      "752/752 [==============================] - ETA: 0s - loss: 1.3392 - accuracy: 0.6472\n",
      "Epoch 7: val_loss improved from 1.57300 to 1.41738, saving model to model\\crop_disease_best_model.h5\n",
      "752/752 [==============================] - 608s 808ms/step - loss: 1.3392 - accuracy: 0.6472 - val_loss: 1.4174 - val_accuracy: 0.6478\n",
      "Epoch 8/20\n",
      "752/752 [==============================] - ETA: 0s - loss: 1.2809 - accuracy: 0.6688 \n",
      "Epoch 8: val_loss did not improve from 1.41738\n",
      "752/752 [==============================] - 10172s 14s/step - loss: 1.2809 - accuracy: 0.6688 - val_loss: 1.5701 - val_accuracy: 0.6024\n",
      "Epoch 9/20\n",
      "752/752 [==============================] - ETA: 0s - loss: 1.2272 - accuracy: 0.6891\n",
      "Epoch 9: val_loss did not improve from 1.41738\n",
      "752/752 [==============================] - 694s 922ms/step - loss: 1.2272 - accuracy: 0.6891 - val_loss: 4.9734 - val_accuracy: 0.4410\n",
      "Epoch 10/20\n",
      "752/752 [==============================] - ETA: 0s - loss: 1.1716 - accuracy: 0.7127\n",
      "Epoch 10: val_loss did not improve from 1.41738\n",
      "752/752 [==============================] - 691s 919ms/step - loss: 1.1716 - accuracy: 0.7127 - val_loss: 1.7013 - val_accuracy: 0.5868\n",
      "Epoch 11/20\n",
      "752/752 [==============================] - ETA: 0s - loss: 1.1300 - accuracy: 0.7246\n",
      "Epoch 11: val_loss did not improve from 1.41738\n",
      "752/752 [==============================] - 676s 899ms/step - loss: 1.1300 - accuracy: 0.7246 - val_loss: 2.1270 - val_accuracy: 0.5078\n",
      "Epoch 12/20\n",
      "752/752 [==============================] - ETA: 0s - loss: 1.1001 - accuracy: 0.7358\n",
      "Epoch 12: val_loss improved from 1.41738 to 1.19912, saving model to model\\crop_disease_best_model.h5\n",
      "752/752 [==============================] - 696s 925ms/step - loss: 1.1001 - accuracy: 0.7358 - val_loss: 1.1991 - val_accuracy: 0.7103\n",
      "Epoch 13/20\n",
      "752/752 [==============================] - ETA: 0s - loss: 1.0880 - accuracy: 0.7410\n",
      "Epoch 13: val_loss did not improve from 1.19912\n",
      "752/752 [==============================] - 646s 859ms/step - loss: 1.0880 - accuracy: 0.7410 - val_loss: 2.3501 - val_accuracy: 0.5030\n",
      "Epoch 14/20\n",
      "752/752 [==============================] - ETA: 0s - loss: 1.0662 - accuracy: 0.7484\n",
      "Epoch 14: val_loss did not improve from 1.19912\n",
      "752/752 [==============================] - 604s 803ms/step - loss: 1.0662 - accuracy: 0.7484 - val_loss: 1.5938 - val_accuracy: 0.6446\n",
      "Epoch 15/20\n",
      "752/752 [==============================] - ETA: 0s - loss: 1.0410 - accuracy: 0.7566\n",
      "Epoch 15: val_loss did not improve from 1.19912\n",
      "752/752 [==============================] - 602s 801ms/step - loss: 1.0410 - accuracy: 0.7566 - val_loss: 2.1581 - val_accuracy: 0.5073\n",
      "Epoch 16/20\n",
      "752/752 [==============================] - ETA: 0s - loss: 1.0288 - accuracy: 0.7608\n",
      "Epoch 16: val_loss improved from 1.19912 to 1.04982, saving model to model\\crop_disease_best_model.h5\n",
      "752/752 [==============================] - 604s 803ms/step - loss: 1.0288 - accuracy: 0.7608 - val_loss: 1.0498 - val_accuracy: 0.7706\n",
      "Epoch 17/20\n",
      "752/752 [==============================] - ETA: 0s - loss: 1.0064 - accuracy: 0.7681\n",
      "Epoch 17: val_loss did not improve from 1.04982\n",
      "752/752 [==============================] - 609s 810ms/step - loss: 1.0064 - accuracy: 0.7681 - val_loss: 1.3116 - val_accuracy: 0.7094\n",
      "Epoch 18/20\n",
      "752/752 [==============================] - ETA: 0s - loss: 1.0030 - accuracy: 0.7690\n",
      "Epoch 18: val_loss improved from 1.04982 to 0.93163, saving model to model\\crop_disease_best_model.h5\n",
      "752/752 [==============================] - 607s 807ms/step - loss: 1.0030 - accuracy: 0.7690 - val_loss: 0.9316 - val_accuracy: 0.7990\n",
      "Epoch 19/20\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.9823 - accuracy: 0.7777\n",
      "Epoch 19: val_loss did not improve from 0.93163\n",
      "752/752 [==============================] - 611s 813ms/step - loss: 0.9823 - accuracy: 0.7777 - val_loss: 1.2118 - val_accuracy: 0.7133\n",
      "Epoch 20/20\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.9850 - accuracy: 0.7758\n",
      "Epoch 20: val_loss improved from 0.93163 to 0.92833, saving model to model\\crop_disease_best_model.h5\n",
      "752/752 [==============================] - 604s 803ms/step - loss: 0.9850 - accuracy: 0.7758 - val_loss: 0.9283 - val_accuracy: 0.7982\n",
      "‚úÖ Model saved as crop_disease_model.h5\n"
     ]
    }
   ],
   "source": [
    "# Now train your model with the generator and callbacks\n",
    "cnn.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(X_train) // 32,\n",
    "    epochs=20,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=len(X_val) // 32,\n",
    "    callbacks=[early_stopping, checkpoint]  # Add both callbacks\n",
    ")\n",
    "\n",
    "# Save the final model\n",
    "cnn.save('model/crop_disease_model.h5')\n",
    "print(\"‚úÖ Model saved as crop_disease_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
